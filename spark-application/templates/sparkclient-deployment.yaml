apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: sparkclient
  name: sparkclient
  namespace: {{ .Values.global.namespace }} 
spec:
  replicas: 1
  selector:
    matchLabels:
      app: sparkclient
  strategy:
    type: Recreate
  template:
    metadata:
      labels:
        app: sparkclient
    spec:
      containers:
        - env:
            - name: KAFKA_CONSUMER_CONFIG
              valueFrom:
                configMapKeyRef:
                  key: KAFKA_CONSUMER_CONFIG
                  name: env
            - name: KAFKA_SERVER
              valueFrom:
                configMapKeyRef:
                  key: KAFKA_SERVER
                  name: env
            - name: S3_END_POINT
              valueFrom:
                configMapKeyRef:
                  key: S3_END_POINT
                  name: env
            - name: S3_PASSWORD
              valueFrom:
                configMapKeyRef:
                  key: S3_PASSWORD
                  name: env
            - name: S3_USER
              valueFrom:
                configMapKeyRef:
                  key: S3_USER
                  name: env
            - name: S3_SOURCE_BUCKET
              valueFrom:
                configMapKeyRef:
                  key: S3_SOURCE_BUCKET
                  name: env
            - name: KAFKA_TOPIC_NAME
              valueFrom:
                configMapKeyRef:
                  key: KAFKA_TOPIC_NAME
                  name: env
            - name: MASTER_HOST_NAME
              value: {{printf "spark://%s:%v" .Values.spark.master_config.ip .Values.spark.master_config.master_port }}
            - name: DRIVER_IP
              valueFrom:
                fieldRef:
                  apiVersion: "v1"
                  fieldPath: "status.podIP"
            - name: DRIVER_HOST
              value: {{.Values.spark.client_config.ip | quote}}
            - name: DRIVER_PORT
              value: {{.Values.spark.client_config.driver_port | quote}}
            - name: DRIVER_BLOCK_MANAGER_PORT
              value: {{.Values.spark.client_config.block_manager_port | quote}}
            - name: EXECUTOR_CORES
              value: {{.Values.spark.all_workers.executor_cores | quote}}
            - name: EXECUTOR_MEMORY
              value: {{.Values.spark.all_workers.executor_memory | quote}}
            - name: MIN_EXECUTOR_NO
              value: {{.Values.spark.all_workers.min_executors | quote}}
            - name: MAX_EXECUTOR_NO
              value: {{.Values.spark.all_workers.max_executors | quote}}
          image: {{printf "%s/%s:%s" .Values.spark.client_image.registry .Values.spark.client_image.repository .Values.spark.client_image.tag}}
          resources:
            requests:
              memory: {{ .Values.spark.client_config.node_resource.requests.memory }}
              cpu: {{ .Values.spark.client_config.node_resource.requests.cpu }}
            limits:
              memory: {{ .Values.spark.client_config.node_resource.limits.memory }}
              cpu: {{ .Values.spark.client_config.node_resource.limits.cpu }}

          name: sparkclient
          ports:
            - containerPort: 4040
            - containerPort: {{.Values.spark.client_config.driver_port}}
            - containerPort: {{.Values.spark.client_config.block_manager_port}}
          volumeMounts:
            - mountPath: /root/.ivy2/jars
              name: spark-packages
            - mountPath: /root/.ivy2/cache
              name: spark-cache
      restartPolicy: Always
      volumes:
        - name: spark-packages
          persistentVolumeClaim:
            claimName: spark-packages
        - name: spark-cache
          persistentVolumeClaim:
            claimName: spark-cache
